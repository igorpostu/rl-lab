{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components and random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib as plt\n",
    "\n",
    "from components.agent import ReplayMemory, DQN, DQNAgent\n",
    "from components.environments import CartPoleEnv\n",
    "from components.utils import set_random_seed, get_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "GAMMA = 0.95\n",
    "EPS = 1\n",
    "EPS_DECAY = 0.995\n",
    "EPS_MIN = 0.1\n",
    "TAU = 0.05\n",
    "\n",
    "MEMORY_CAPACITY = 4000\n",
    "\n",
    "BATCH_SIZE = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DQN agent and the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CartPoleEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(env.n_actions, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, env.n_observations)\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.Adam(get_parameters(model), lr=LR)\n",
    "dqn = DQN(model, criterion, optimiser)\n",
    "\n",
    "memory = ReplayMemory(MEMORY_CAPACITY)\n",
    "\n",
    "agent = DQNAgent(\n",
    "    dqn, memory,\n",
    "    gamma=GAMMA,\n",
    "    eps=EPS,\n",
    "    eps_decay=EPS_DECAY,\n",
    "    eps_min=EPS_MIN,\n",
    "    tau=TAU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = agent.train(env, 1000, batch_size=BATCH_SIZE, evaluation_episodes=25, apply_best_model=True)\n",
    "print(\"Final score:\", agent.evaluate(env, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
